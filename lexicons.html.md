# lexicons


<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->

------------------------------------------------------------------------

<a
href="https://github.com/polsci/textplumber/blob/main/textplumber/lexicons.py#L15"
target="_blank" style="float:right; font-size:smaller">source</a>

### LexiconCountVectorizer

>  LexiconCountVectorizer (feature_store:textplumber.store.TextFeatureStore,
>                              lexicons:dict, lowercase:bool=True)

*A Sci-kit Learn pipeline component to get document-level counts for one
or more lexicons. This component should be used after the
SpacyPreprocessor component with the same feature store.*

<table>
<colgroup>
<col style="width: 6%" />
<col style="width: 25%" />
<col style="width: 34%" />
<col style="width: 34%" />
</colgroup>
<thead>
<tr>
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>feature_store</td>
<td>TextFeatureStore</td>
<td></td>
<td>the feature store to use - this should be the same feature store
used in the SpacyPreprocessor component</td>
</tr>
<tr>
<td>lexicons</td>
<td>dict</td>
<td></td>
<td>the lexicons to use - a dictionary with the lexicon name as the key
and the lexicon (a list of tokens to count) as the value</td>
</tr>
<tr>
<td>lowercase</td>
<td>bool</td>
<td>True</td>
<td>whether to lowercase the tokens</td>
</tr>
</tbody>
</table>

------------------------------------------------------------------------

<a
href="https://github.com/polsci/textplumber/blob/main/textplumber/lexicons.py#L52"
target="_blank" style="float:right; font-size:smaller">source</a>

### get_empath_lexicons

>  get_empath_lexicons ()

*Get the empath lexicons from the empath github repo.*

TODO: add an example.
