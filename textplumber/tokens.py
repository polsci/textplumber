"""Extract token features."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/20_tokens.ipynb.

# %% auto 0
__all__ = ['TokensVectorizer']

# %% ../nbs/20_tokens.ipynb 3
from sklearn.base import BaseEstimator, TransformerMixin
from .store import TextFeatureStore
from .core import pass_tokens
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer

# %% ../nbs/20_tokens.ipynb 4
class TokensVectorizer(BaseEstimator, TransformerMixin):
    """ Sci-kit Learn pipeline component to extract token features. This component should be used after the SpacyPreprocessor component with the same feature store.
        The component gets the tokens from the feature store and returns a matrix of counts (via CountVectorizer) or Tf-idf scores (using TfidfVectorizer). """
    
    def __init__(self, 
                 feature_store: TextFeatureStore, # the feature store to use - this should be the same feature store used in the SpacyPreprocessor component
                 vectorizer_type:str = 'count', # the type of vectorizer to use - 'count' for CountVectorizer or 'tfidf' for TfidfVectorizer
                 lowercase:bool = False, # whether to lowercase the tokens 
                 stop_words:list[str]|None = None, # the stop words to use - passed to CountVectorizer or TfidfVectorizer
                 min_df:float|int = 1, # the minimum document frequency to use - passed to CountVectorizer or TfidfVectorizer
                 max_df:float|int = 1.0, # the maximum document frequency to use - passed to CountVectorizer or TfidfVectorizer
                 max_features:int = None, # the maximum number of features to use - passed to CountVectorizer or TfidfVectorizer
                 ngram_range:tuple = (1, 1), # the ngram range to use (min_n, max_n) - passed to CountVectorizer or TfidfVectorizer
                 vocabulary:list|None = None, # list of tokens to use - passed to CountVectorizer or TfidfVectorizer
                 encoding:str = 'utf-8', # the encoding to use - passed to CountVectorizer or TfidfVectorizer 
                 decode_error:str = 'ignore' # what to do if there is an error decoding 'strict', 'ignore', 'replace' - passed to CountVectorizer or TfidfVectorizer
                ):
        self.vectorizer_type = vectorizer_type
        self.feature_store = feature_store
        self.lowercase = lowercase
        self.stop_words = stop_words
        self.min_df = min_df
        self.max_df = max_df
        self.max_features = max_features
        self.ngram_range = ngram_range
        self.vocabulary = vocabulary
        self.encoding = encoding
        self.decode_error = decode_error

    def fit(self, X, y=None):
        """ Fit the vectorizer to the tokens in the feature store. """
        if self.vectorizer_type == 'tfidf':
            self.vectorizer_ = TfidfVectorizer(tokenizer=pass_tokens, lowercase=False, token_pattern = None, stop_words=self.stop_words, min_df=self.min_df, max_df=self.max_df, max_features=self.max_features, ngram_range=self.ngram_range, vocabulary= self.vocabulary, encoding=self.encoding, decode_error=self.decode_error)
        elif self.vectorizer_type == 'count':
            self.vectorizer_ = CountVectorizer(tokenizer=pass_tokens, lowercase=False, token_pattern = None, stop_words=self.stop_words, min_df=self.min_df, max_df=self.max_df, max_features=self.max_features, ngram_range=self.ngram_range, vocabulary= self.vocabulary, encoding=self.encoding, decode_error=self.decode_error)
        else:
            raise ValueError("Invalid vectorizer_type. Use 'tfidf' or 'count'.")
        return self.vectorizer_.fit(self.feature_store.get_tokens_from_texts(X, lowercase = self.lowercase), y)
    
    def transform(self, X):
        """ Transform the texts to a matrix of counts or tf-idf scores. """
        return self.vectorizer_.transform(self.feature_store.get_tokens_from_texts(X, lowercase = self.lowercase))
    
    def get_feature_names_out(self, input_features=None):
        """ Get the feature names out from the vectorizer. """
        return self.vectorizer_.get_feature_names_out(input_features)
    
    
